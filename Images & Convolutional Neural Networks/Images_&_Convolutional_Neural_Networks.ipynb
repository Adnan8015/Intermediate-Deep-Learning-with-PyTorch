{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Images with PyTorch"
      ],
      "metadata": {
        "id": "AiTqKenjKMUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Images to PyTorch**"
      ],
      "metadata": {
        "id": "tjLtkdbAAkJl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlczh8s7AX-v"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Resize((128, 128)),   ### Ensure all images are same size\n",
        "])\n",
        "\n",
        "dataset_train = ImageFolder(\n",
        "    \"data/clouds_train\",\n",
        "    transform=train_transforms,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying images**"
      ],
      "metadata": {
        "id": "7VChK_FTKrG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = DataLoader(\n",
        "      dataset_train,\n",
        "      shuffle=True,\n",
        "      batch_size=1,\n",
        ")\n",
        "\n",
        "image, label = next(iter(dataloader_train))\n",
        "print(image.shape)\n",
        "\n",
        "\n",
        "image = image.squeeze().permute(1, 2, 0)\n",
        "print(image.shape)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mvw0AqHZKs7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation**"
      ],
      "metadata": {
        "id": "LT1Q2JgLK-Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.RandomRotation(45),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Resize((128, 128)),\n",
        "])\n",
        "\n",
        "dataset_train = ImageFolder(\n",
        "\"data/clouds/train\",\n",
        "transform=train_transforms,\n",
        ")"
      ],
      "metadata": {
        "id": "n13pkEAkLALh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Compose two transformations, the first, to parse the image to a tensor, and one to resize the image to 128 by 128, assigning them to train_transforms.\n",
        "Use ImageFolder to define dataset_train, passing it the directory path to the data (\"clouds_train\") and the transforms defined earlier.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "# Compose transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((128 , 128)),\n",
        "])\n",
        "\n",
        "# Create Dataset using ImageFolder\n",
        "dataset_train = ImageFolder(\n",
        "    \"clouds_train\",\n",
        "    transform=train_transforms,\n",
        ")"
      ],
      "metadata": {
        "id": "oFV2dRxfLN-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Add two more transformations to train_transforms to perform a random horizontal flip and then a rotation by a random angle between 0 and 45 degrees.\n",
        "Reshape the image tensor from the DataLoader to make it suitable for display.\n",
        "Display the image\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    # Add horizontal flip and rotation\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(45),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((128, 128)),\n",
        "])\n",
        "\n",
        "dataset_train = ImageFolder(\n",
        "  \"clouds_train\",\n",
        "  transform=train_transforms,\n",
        ")\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "  dataset_train, shuffle=True, batch_size=1\n",
        ")\n",
        "\n",
        "image, label = next(iter(dataloader_train))\n",
        "# Reshape the image tensor\n",
        "image = image.squeeze().permute(1, 2, 0)\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7HKIyqMOLb8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "ZAO3CUpCLh2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Layer**"
      ],
      "metadata": {
        "id": "8FmSmb2n2wdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "In a convolutional layer, parameters are collected in one or more small grids called filters. These filters slide over the input,\n",
        "performing convolution operations at each position to create a feature map.\n",
        "\n",
        "Here, we slide a 3-by-3 filter over a 5-by-5 input to get a 3-by-3 feature map. A feature map preserves spatial patterns from the input\n",
        "and uses fewer parameters than a linear layer. In a convolutional layer, we can use many filters. Each results in a separate feature map.\n",
        "\n",
        "Finally, we apply activations to each feature map. All the feature maps combined form the output of a convolutional layer.\n",
        "In PyTorch, we use nn.Conv2d to define a convolutional layer. We pass it the number of input and output feature maps.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ygk4IpRNLjrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolution**"
      ],
      "metadata": {
        "id": "D7dYVN793ZD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "In the context of deep learning, a convolution is the dot product between two arrays, the input patch and the filter.\n",
        "Dot product is element-wise multiplication between the corresponding elements.\n",
        "\n",
        "We sum all values in the outcome array, returning a single value that becomes part of the output feature map.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EZvInvHO3bn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-padding**"
      ],
      "metadata": {
        "id": "FBoXzMcs4j_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Before a convolutional layer processes its input, we often add zeros around it, a technique called zero-padding.\n",
        "This is done with the padding argument in the convolutional layer. It helps maintain the spatial dimensions of the input and output,\n",
        "and ensures equal treatment of border pixels. Without padding, the pixels at the border would have a filter slide over them fewer times resulting in information loss.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "nn.Conv2d(\n",
        "    3, 32, kernel_size=3, padding=1\n",
        ")"
      ],
      "metadata": {
        "id": "5DOD6V_64mSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Max Pooling**"
      ],
      "metadata": {
        "id": "HbnaS-St47fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Max Pooling is another operation commonly used after convolutional layers. In it, we slide a non-overlapping window over the input.\n",
        "At each position, we select the maximum value from the window to pass forward. Using a window of two-by-two as shown here halves the input's height and width.\n",
        "This operation reduces the spatial dimensions of the feature maps, reducing the number of parameters and computational complexity in the network.\n",
        "\n",
        "In PyTorch, we use nn.MaxPool2d to define a max pooling layer, passing it the kernel size\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "nn.MaxPool2d(kernel_size=2)"
      ],
      "metadata": {
        "id": "HosKUqgF5Ayh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Network**"
      ],
      "metadata": {
        "id": "1gjR-y6S7TUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Our Convolutional Neural Network will have two parts: a feature extractor and a classifier.\n",
        "\n",
        "Feature extractor has convolution, activation, and max pooling layers repeated twice. The first two arguments in Conv2d are the numbers of input\n",
        "and output feature maps. The first Conv2d has three input feature maps corresponding to the RGB channels. We use filters of size 3 by 3 set by the kernel_size argument\n",
        "and zero-padding by setting padding to 1. For max pooling, we use the MaxPool2d layer with a window of size 2 to halve the feature map in height and width.\n",
        "Finally, we flatten the feature extractor output into a vector.\n",
        "\n",
        "Our classifier consists of a single linear layer. The output is the number of target classes, the model's argument.\n",
        "\n",
        "The forward method applies the extractor and classifier to the input image.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "eh97URmC7Uz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Define the feature_extractor part of the model by adding another convolutional layer with 64 output feature maps, the ELU activation,\n",
        "and a max pooling layer with a window of size two; at the end, flatten the output.\n",
        "\n",
        "Define the classifier part of the model as a single linear layer with a number of inputs that reflects an input image of 64x64 and the feature extractor defined;\n",
        "the classifier should have num_classes outputs.\n",
        "\n",
        "In the forward() method, pass the input image x first through the feature extractor and then through the classifier.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        # Define feature extractor\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(64*16*16 , num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through feature extractor and classifier\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4UevWxI38jBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Image Classifiers"
      ],
      "metadata": {
        "id": "ChIZMMHv9BJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image classifier training loop**"
      ],
      "metadata": {
        "id": "4TEsv8cq-DKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(num_classes=7)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for images, labels in dataloader_train:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "vU3XrVpe-FK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Define train_transforms by composing together five transformations: a random horizontal flip, random rotation (by angle from 0 to 45 degrees),\n",
        "random automatic contrast adjustment, parsing to tensor, and resizing to 64 by 64 pixels.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Define transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(45),\n",
        "    transforms.RandomAutocontrast(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((64 , 64)),\n",
        "])\n",
        "\n",
        "dataset_train = ImageFolder(\n",
        "  \"clouds_train\",\n",
        "  transform=train_transforms,\n",
        ")\n",
        "dataloader_train = DataLoader(\n",
        "  dataset_train, shuffle=True, batch_size=16\n",
        ")"
      ],
      "metadata": {
        "id": "CdzK1swE9EaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Define the model using your Net class with num_classes set to 7 and assign it to net.\n",
        "Define the loss function as cross-entropy loss and assign it to criterion.\n",
        "Define the optimizer as Adam, passing it the model's parameters and the learning rate of 0.001, and assign it to optimizer.\n",
        "Start the training for-loop by iterating over training images and labels of dataloader_train.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Define the model\n",
        "net = Net(num_classes = 7)\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(net.parameters() , lr = 0.001)\n",
        "\n",
        "for epoch in range(3):\n",
        "    running_loss = 0.0\n",
        "    # Iterate over training batches\n",
        "    for images, labels in dataloader_train:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader_train)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "t9KucgpK-1Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Image Classifiers"
      ],
      "metadata": {
        "id": "rozcxoQg_AvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Averaging multi-class metrics**"
      ],
      "metadata": {
        "id": "p_BPe3zYGBVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "For example, for recall, we pass average as none to get seven recall scores, one for each class, or we can set it to micro, macro, or weighted.\n",
        "But when to use each of them? If our dataset is highly imbalanced, micro-average is a good choice because it takes into account the class imbalance.\n",
        "Macro-averaging treats all classes equally regardless of their size. It can be a good choice if you care about performance on smaller classes,\n",
        "\n",
        "even if those classes have fewer data points. Weighted averaging is a good choice when class imbalance is a concern and you consider errors in larger classes as more important.\n",
        "\n",
        "\n",
        "\n",
        "When to use each:\n",
        " Micro: Imbalanced datasets\n",
        " Macro: Care about performance on small classes\n",
        " Weighted: Consider errors in larger classes as more important\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from torchmetrics import Recall\n",
        "recall_per_class = Recall(task=\"multiclass\", num_classes=7, average=None)\n",
        "recall_micro = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
        "recall_macro = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
        "recall_weighted = Recall(task=\"multiclass\", num_classes=7, average=\"weighted\")"
      ],
      "metadata": {
        "id": "ZkVON9y5GC0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Loop**"
      ],
      "metadata": {
        "id": "grnlGKryG0WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Precision, Recall\n",
        "\n",
        "metric_precision = Precision(\n",
        "      ask=\"multiclass\", num_classes=7, average=\"macro\"\n",
        "  )\n",
        "\n",
        "metric_recall = Recall(\n",
        "      task=\"multiclass\", num_classes=7, average=\"macro\"\n",
        "  )\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader_test:\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        metric_precision(preds, labels)\n",
        "        metric_recall(preds, labels)\n",
        "precision = metric_precision.compute()\n",
        "recall = metric_recall.compute()"
      ],
      "metadata": {
        "id": "_YFDFz7IGXzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Let's evaluate our cloud classifier with precision and recall to see how well it can classify the seven cloud types. In this multi-class classification task it is important how you average the scores over classes. Recall that there are four approaches:\n",
        "\n",
        "Not averaging, and analyzing the results per class;\n",
        "Micro-averaging, ignoring the classes and computing the metrics globally;\n",
        "Macro-averaging, computing metrics per class and averaging them;\n",
        "Weighted-averaging, just like macro but with the average weighted by class size.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Define precision and recall metrics calculated globally on all examples.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Define metrics\n",
        "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
        "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader_test:\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        metric_precision(preds, labels)\n",
        "        metric_recall(preds, labels)\n",
        "\n",
        "precision = metric_precision.compute()\n",
        "recall = metric_recall.compute()\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Change your code to compute separate recall and precision metrics for each class and average them with a simple average.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Define metrics\n",
        "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
        "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader_test:\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        metric_precision(preds, labels)\n",
        "        metric_recall(preds, labels)\n",
        "\n",
        "precision = metric_precision.compute()\n",
        "recall = metric_recall.compute()\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")"
      ],
      "metadata": {
        "id": "UhC_vaHh_IAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "While aggregated metrics are useful indicators of the model's performance, it is often informative to look at the metrics per class.\n",
        " This could reveal classes for which the model underperforms.\n",
        "\n",
        "In this exercise, you will run the evaluation loop again to get our cloud classifier's precision, but this time per-class.\n",
        "Then, you will map these score to the class names to interpret them. As usual, Precision has already been imported for you. Good luck!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Define a precision metric appropriate for per-class results.\n",
        "Calculate the precision per class by finishing the dict comprehension, iterating over the .items() of the .class_to_idx attribute of dataset_test.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Define precision metric\n",
        "metric_precision = Precision(\n",
        "    task=\"multiclass\", num_classes=7, average = None\n",
        ")\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader_test:\n",
        "        outputs = net(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        metric_precision(preds, labels)\n",
        "precision = metric_precision.compute()\n",
        "\n",
        "# Get precision per class\n",
        "precision_per_class = {\n",
        "    k: precision[v].item()\n",
        "    for k, v\n",
        "    in dataset_test.class_to_idx.items()\n",
        "}\n",
        "print(precision_per_class)"
      ],
      "metadata": {
        "id": "Zd8GvDRFJ10J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}